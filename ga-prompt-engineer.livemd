# prompt-engineer-ga

## Introduction

```elixir
# First, let's set up our dependencies
Mix.install([
  {:httpoison, "~> 2.0"},
  {:jason, "~> 1.4"}
])

defmodule Individual do
  @moduledoc """
  Represents a single prompt individual in our population.
  Each individual contains a prompt template made up of different components
  that can be mutated and evolved.
  """
  defstruct [:template_parts, :fitness]
end

defmodule PromptEvaluator do
  @moduledoc """
  Handles communication with Ollama API and evaluates the quality of generated code
  based on various metrics.
  """
  @base_url "http://localhost:11434/api"
  
  def evaluate_prompt_result(generated_code) do
    # Here we evaluate the quality of the code generated by our prompt
    evaluation_prompt = """
    Evaluate this code and provide scores in the following format:
    
    SCORES (1-10):
    Clarity: [score]
    Efficiency: [score]
    Correctness: [score]
    Style: [score]
    Documentation: [score]
    
    Provide a brief explanation after each score.
    Calculate and show the TOTAL SCORE as an average.
    
    CODE TO EVALUATE:
    #{generated_code}
    """
    
    case generate_with_ollama(evaluation_prompt) do
      {:ok, evaluation_text} -> extract_score(evaluation_text)
      {:error, _} -> {0.0, "Failed to evaluate"}
    end
  end

  def generate_with_ollama(prompt) do
    url = @base_url <> "/generate"
    
    body = %{
      model: "codellama:7b",
      prompt: prompt,
      stream: false,
      options: %{
        num_predict: 1000
      }
    }
    
    try do
      response = HTTPoison.post!(url, Jason.encode!(body), 
        [{"Content-Type", "application/json"}],
        [timeout: 60_000, recv_timeout: 60_000])
        
      with {:ok, decoded} <- Jason.decode(response.body),
           %{"response" => text} <- decoded do
        {:ok, text}
      else
        _ -> {:error, "Failed to decode response"}
      end
    rescue
      e -> {:error, "HTTP error: #{inspect(e)}"}
    end
  end
  
  defp extract_score(evaluation_text) do
    case Regex.run(~r/(?:TOTAL SCORE|Average)[:\s]+(\d+\.?\d*)/, evaluation_text) do
      [_, score] ->
        case Float.parse(score) do
          {num, _} -> {num, evaluation_text}
          :error -> {0.0, "Failed to parse score"}
        end
      nil -> {0.0, "No score found"}
    end
  end
end

defmodule PromptGA do
  @moduledoc """
  Implements the genetic algorithm for evolving prompts.
  """
  
  # Define template parts for constructing prompts
  @template_parts [
    # Context setting
    ["Given a programming task,", "As an expert programmer,", "You are a skilled developer,"],
    
    # Task description
    ["write code that", "implement a function to", "create a program that"],
    
    # Requirements
    ["is efficient and well-documented.", "follows best practices and includes error handling.", "is clean, maintainable, and properly tested."],
    
    # Output specification
    ["Provide the solution in", "Write the implementation using", "Show the code in"],
    
    # Language specification
    ["Python", "JavaScript", "Ruby"],
    
    # Additional instructions
    ["Include helpful comments.", "Add documentation for key components.", "Explain any complex logic."]
  ]

  def run(config) do
    population = initialize_population(config.population_size)
    run_evolution(population, config, 1)
  end

  defp initialize_population(size) do
    for _ <- 1..size do
      %Individual{
        template_parts: Enum.map(@template_parts, &Enum.random/1),
        fitness: nil
      }
    end
  end

  defp run_evolution(population, config, generation) do
    evaluated_pop = evaluate_population(population)
    best = Enum.max_by(evaluated_pop, & &1.fitness)
    
    IO.puts("\nGeneration #{generation}")
    IO.puts("Best Fitness: #{best.fitness}")
    IO.puts("Best Prompt:")
    IO.puts(create_prompt(best))

    if generation >= config.max_generations do
      best
    else
      new_population = 
        evolve_population(evaluated_pop, config)
        |> Enum.map(&maybe_mutate(&1, config.mutation_rate))

      run_evolution(new_population, config, generation + 1)
    end
  end

  defp evaluate_population(population) do
    Enum.map(population, &evaluate_individual/1)
  end

  defp evaluate_individual(individual) do
    prompt = create_prompt(individual)
    
    # First, generate code using the prompt
    case PromptEvaluator.generate_with_ollama(prompt) do
      {:ok, generated_code} ->
        # Then evaluate the generated code
        {score, _explanation} = PromptEvaluator.evaluate_prompt_result(generated_code)
        %{individual | fitness: score}
      {:error, _} ->
        %{individual | fitness: 0.0}
    end
  end

  def create_prompt(individual) do
    Enum.join(individual.template_parts, " ")
  end

  defp evolve_population(population, config) do
    elites = 
      population
      |> Enum.sort_by(& &1.fitness, :desc)
      |> Enum.take(config.elite_size)

    num_children = config.population_size - config.elite_size

    children =
      for _ <- 1..num_children do
        parent1 = select_parent(population, config.tournament_size)
        parent2 = select_parent(population, config.tournament_size)
        crossover(parent1, parent2)
      end

    elites ++ children
  end

  defp select_parent(population, tournament_size) do
    population
    |> Enum.take_random(tournament_size)
    |> Enum.max_by(& &1.fitness)
  end

  defp crossover(parent1, parent2) do
    point = :rand.uniform(length(parent1.template_parts))
    {parts1, parts2} = Enum.split(parent1.template_parts, point)
    {parts3, parts4} = Enum.split(parent2.template_parts, point)
    
    %Individual{
      template_parts: parts1 ++ parts4,
      fitness: nil
    }
  end

  defp maybe_mutate(individual, rate) do
    template_parts = Enum.map(Enum.with_index(individual.template_parts), fn {part, idx} ->
      if :rand.uniform() < rate do
        Enum.random(Enum.at(@template_parts, idx))
      else
        part
      end
    end)
    
    %{individual | template_parts: template_parts, fitness: nil}
  end
end

# Configuration for running the algorithm
config = %{
  population_size: 10,    # Start with a small population for testing
  max_generations: 5,     # Fewer generations for initial testing
  mutation_rate: 0.1,     # 10% chance of mutation
  elite_size: 2,         # Keep the top 2 individuals
  tournament_size: 3      # Tournament selection size
}

IO.puts("Starting Prompt Evolution...")
best_solution = PromptGA.run(config)

IO.puts("\nFinal Best Solution:")
IO.puts("==================")
IO.puts("Fitness: #{best_solution.fitness}")
IO.puts("\nPrompt:")
IO.puts(PromptGA.create_prompt(best_solution))
```
